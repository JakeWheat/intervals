
figure out how to run more quickcheck tests:
time stack test --test-arguments "--quickcheck-tests 10000"

figure out how to generate bigger individual data values for the
   benchmarking

do writeup on the optimisation so far (maybe try to benchmark with
   real data first)

Implement u_minus with payload:
packRelation, unpackRelation, modelUMinusRelation, uMinusRelation
these are the above with a payload for each entry

separate out into different modules:
model, intermediate implementations, final implementation


Implement the self times using slow join approach
try to test using the generator approach
Implement self times using fast streaming

get some real world data to benchmark

implement the algorithm in postgres and compare times


feature ideas:
add more interval operations with tests



optimisation ideas:
use a variation of vector or list of vectors to represent interval
  sets
use completely unpacked columnar data representation
benchmark running pack on already packed
benchmark running isPacked function
make sure we don't repeat packing
get ghc profiling and code coverage working (coverage is more useful
   for monitoring the effectiveness of the testing)

make sure the paylods aren't copied around (risk when moving to vector
or unpacked vector)

automation:

automatically detect and highlight performance changes from code
version to version, and see a graph of the performance changes over
many code versions

compare different implementations of code to choose the fastest
version. This might change outside of code changes:
depends on the data
can depend on the external environment e.g. the os, or the hardware

so want to be able to keep some alternatives alive and be able to go
back and check them easily from time to time.

